# PretrainTransformerOnSQUAD
Fine tuning Bert model on SQUAD2 dataset

Follow [huggingFace example - How to fine-tune a model on question answering](https://huggingface.co/transformers/notebooks.html), the main contribution is to create image which it can run with distribued training and hyper-parameter tunning service.

Some other references:

1. [Building a QA System with BERT on Wikipedia](https://qa.fastforwardlabs.com/pytorch/hugging%20face/wikipedia/bert/transformers/2020/05/19/Getting_Started_with_QA.html)
2. [HuggingFace Transformer Question-Answering Code Examples](https://github.com/huggingface/transformers/tree/master/examples/question-answering)
3. [kamalkraj/BERT-SQuAD](https://github.com/kamalkraj/BERT-SQuAD/tree/master/training)
